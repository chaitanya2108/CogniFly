# CogniFly 🎓✨
*Transforming Text into Immersive Learning Experiences*

## 🚀 Overview

**CogniFly** is a revolutionary AI-powered learning platform designed to convert dense and static educational content into dynamic, personalized video experiences. Whether a learner is neurodivergent, multilingual, or simply more visual in learning style, CogniFly ensures that education becomes accessible, engaging, and effective for all.

> “Because education should be felt, seen, and experienced, not just read.”

---

## 📌 Problem Statement

Traditional learning resources are outdated, inaccessible to diverse learners, and not optimized for engagement or comprehension:
- 251M children remain out of school globally (UNESCO, 2024)
- 40% of students lack access to education in a language they understand
- Over 1 in 4 U.S. adults have a disability, including cognitive impairments
- Visual learning enhances retention by up to 400%

---

## 💡 Our Solution

CogniFly addresses these challenges with a comprehensive AI toolkit:

- **Text-to-Video Generation**  
  Seamlessly turn PDFs or text into engaging AI-generated videos.

- **Multilingual Transcripts & Captions**  
  Support for rare dialects and sign language for inclusivity.

- **Neurodivergent-Friendly Modes**  
  Personalized interfaces for individuals with ADHD, dyslexia, and sensory sensitivities.

- **Interactive Learning Modules**  
  Quizzes, annotations, and dynamic visual cues enhance understanding and retention.

---

## 🧠 Tech Stack

- **Design**: Figma  
- **Frontend**: React.js  
- **Backend**: Django  
- **AI/ML**: Hugging Face APIs for text-to-speech and video synthesis

---

## 🛠 System Architecture

- Input: PDF/Text → Split into Scenes  
- Process:
  - Video Generator (Text-to-Video)
  - Narrator (Text-to-Audio)
  - Captioner (Text-to-Text)
- Output: Final multilingual, interactive video content

(See [System Architecture Diagram on page 7 of the deck](#))

---

## 💻 Platform UI

The UI enables:
- Viewing lesson plans
- Navigating transcripts and videos
- Toggling between languages
- Personalizing playback for learning preferences

(See screenshots on page 8–9 of the deck)

---

## 🔮 Future Scope

- 🌐 Real-time sign language & multilingual narration
- 🎮 Gamified experiences with AR/VR and AI-driven adaptability
- 🧑‍🤝‍🧑 Community-driven platform for collaborative learning creation

---

## 📚 Resources & References

- UNESCO: [Global Education Report](https://news.un.org/en/story/2024/10/1156366)  
- CDC: [Disability Infographic](https://www.cdc.gov/disability-and-health/articles-documents/disability-impacts-all-of-us-infographic.html)  
- LMC: [Visual Learning Insights](https://www.lmc.org/news-publications/magazine/july-aug-2023/message-matters-july-2023/)  

---

## 🙌 Team & Acknowledgements

Built for **Philly CodeFest** with a passion for accessible education and immersive technology. Special thanks to the organizers, mentors, and everyone supporting inclusive learning innovation.

---
